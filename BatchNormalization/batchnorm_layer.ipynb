{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Layer Implementations: BatchNormalization BN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Students: Juan Sebastián Barreto Jimenez y Juan Camilo Devia Bastos\n",
    "\n",
    "Consultant: Ing. Eduardo Andrés Gerlien Reyes\n",
    "\n",
    "Client: Ing. Olga Lucía Quintero Montoya"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avoid warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avoid warnings in terminal\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import BatchNormalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1. 2. 3. 4.]\n",
      " [1. 2. 3. 4.]], shape=(2, 4), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "epsilon = 0#.000001\n",
    "# Linear data\n",
    "#data_x = np.array([1,1.5,2,2.5,3,3.5,4,4.5,5,5.5,6],dtype=float)\n",
    "#data_y = np.array([0.169610272, 0.283395813, 0.386358738, 0.470227872, 0.433281294, 0.600267648, 0.73833898, 0.79031502, 0.877464268, 0.843564462, 0.964438917],,dtype=float)\n",
    "\n",
    "# Matrix Data: 3x4x4\n",
    "#data_x = np.array([[[[[6,6,6,6],[6,2,2,6],[6,2,2,6],[6,6,6,6]],[[8,5,5,8],[8,0,0,8],[8,0,0,8],[8,5,5,8]],[[5,6,6,5],[8,2,1,9],[9,1,2,8],[6,5,5,6]]],[[[6,6,6,6],[6,2,2,6],[6,2,2,6],[6,6,6,6]],[[8,5,5,8],[8,0,0,8],[8,0,0,8],[8,5,5,8]],[[5,6,6,5],[8,2,1,9],[9,1,2,8],[6,5,5,6]]]]],dtype=float)\n",
    "\n",
    "data_x = np.array([[1,2,3,4],[1,2,3,4]],dtype=float)\n",
    "\n",
    "\n",
    "#data_x = np.array([[1,2,3,4],[1,2,3,4]],dtype=float)\n",
    "#data_y = np.array([[1,2,3,4],[1,2,3,4]],dtype=float)\n",
    "\n",
    "data_x = tf.constant(data_x)\n",
    "#data_x = tf.random.uniform((3,100,100))\n",
    "data_y = data_x\n",
    "print(data_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layer BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1/1 [==============================] - 0s 255ms/step - loss: nan\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 7ms/step - loss: nan\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 6ms/step - loss: nan\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 6ms/step - loss: nan\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 6ms/step - loss: nan\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 6ms/step - loss: nan\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
      "x: tf.Tensor(\n",
      "[[1. 2. 3. 4.]\n",
      " [1. 2. 3. 4.]], shape=(2, 4), dtype=float64)\n",
      "moving_mean: [1. 2. 3. 4.]\n",
      "moving_variance: [9.313226e-10 9.313226e-10 9.313226e-10 9.313226e-10]\n",
      "gamma: None\n",
      "beta: None\n",
      "epsilon: 0\n",
      "Batch Size:  [<KerasTensor: shape=(None, 4) dtype=float64 (created by layer 'batch_normalization_1_input')>]\n",
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "bn = BatchNormalization(axis=1,momentum=0.5, epsilon=epsilon,\n",
    "    beta_initializer='zeros', gamma_initializer='ones',\n",
    "    moving_mean_initializer='ones', moving_variance_initializer='ones',\n",
    "    fused=False, scale=False, center=False)\n",
    "model = Sequential(bn)\n",
    "model.compile(optimizer='sgd',loss='mean_squared_error')\n",
    "model.fit(x=data_x, y=data_y, epochs=30)\n",
    "\n",
    "print(\"x:\", data_x)\n",
    "print(\"moving_mean:\", bn.moving_mean.numpy())\n",
    "print(\"moving_variance:\", bn.moving_variance.numpy())\n",
    "print(\"gamma:\", bn.gamma)\n",
    "print(\"beta:\", bn.beta)\n",
    "print(\"epsilon:\", bn.epsilon)\n",
    "print(\"Batch Size: \", model.inputs)\n",
    "\n",
    "print(model.predict(data_x))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
